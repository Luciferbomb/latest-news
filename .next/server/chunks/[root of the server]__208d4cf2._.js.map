{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}},
    {"offset": {"line": 60, "column": 0}, "map": {"version":3,"sources":["file:///Users/ashutoshranjan/test/latest-news/src/app/api/voice-assistant/route.ts"],"sourcesContent":["import { NextResponse } from 'next/server';\n\n// API keys - in production, these should be in environment variables\nconst OPENAI_API_KEY = process.env.OPENAI_API_KEY;\n\n// Define a type for the voice assistant request\ninterface VoiceAssistantRequest {\n  query: string;\n  sessionId?: string;\n}\n\n// Define a type for the voice assistant response\ninterface VoiceAssistantResponse {\n  answer: string;\n  confidence: number;\n  isTechQuestion: boolean;\n  source?: string;\n}\n\n// System prompt for OpenAI to ensure it responds only to tech questions\nconst SYSTEM_PROMPT = `You are a helpful AI assistant specialized in technology topics.\nYou should ONLY answer questions related to technology, AI, programming, computers, \nelectronics, software, hardware, and related technical fields.\n\nIf a user asks a question that is not related to technology, politely decline to answer and\nexplain that you can only provide information about technology topics.\n\nKeep your answers concise (maximum 3 sentences), accurate, and informative. Focus on the latest \nadvancements and developments in AI and technology.`;\n\n// Tech-related keywords to determine if a question is about technology\nconst TECH_KEYWORDS = [\n  'ai', 'artificial intelligence', 'machine learning', 'ml', 'deep learning', \n  'neural network', 'technology', 'software', 'hardware', 'computer', 'programming',\n  'code', 'algorithm', 'data', 'cloud', 'internet', 'web', 'app', 'application',\n  'device', 'robot', 'robotics', 'automation', 'cyber', 'digital', 'electronic',\n  'processor', 'chip', 'semiconductor', 'server', 'network', 'browser', 'language',\n  'framework', 'library', 'api', 'interface', 'database', 'storage', 'memory',\n  'gpu', 'cpu', 'quantum', 'virtual reality', 'vr', 'augmented reality', 'ar',\n  'blockchain', 'cryptocurrency', 'crypto', 'bitcoin', 'ethereum', 'nft',\n  'security', 'encryption', 'privacy', 'streaming', 'video', 'audio', 'voice',\n  'assistant', 'chatbot', 'gpt', 'llm', 'large language model', 'transformer',\n  'openai', 'google', 'microsoft', 'apple', 'amazon', 'meta', 'facebook',\n  'twitter', 'x', 'social media', 'search engine', 'browser', 'mobile', 'phone',\n  'smartphone', 'tablet', 'laptop', 'desktop', 'server', 'cloud computing',\n  'saas', 'paas', 'iaas', 'devops', 'agile', 'scrum', 'kanban', 'git', 'github',\n  'gitlab', 'bitbucket', 'coding', 'development', 'developer', 'engineer',\n  'engineering', 'computer science', 'cs', 'information technology', 'it'\n];\n\n/**\n * Checks if a query is related to technology\n */\nfunction isTechQuestion(query: string): boolean {\n  const lowerQuery = query.toLowerCase();\n  return TECH_KEYWORDS.some(keyword => lowerQuery.includes(keyword.toLowerCase()));\n}\n\n/**\n * Try to get a response from OpenAI\n */\nasync function getOpenAIResponse(query: string): Promise<VoiceAssistantResponse | null> {\n  if (!OPENAI_API_KEY) return null;\n  \n  try {\n    const techCheck = isTechQuestion(query);\n    \n    // If not a tech question, return early with a standard response\n    if (!techCheck) {\n      return {\n        answer: \"I'm sorry, I can only answer questions related to technology, AI, and computing. Please ask me about tech topics.\",\n        confidence: 0.9,\n        isTechQuestion: false,\n        source: \"policy\"\n      };\n    }\n    \n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n        'Authorization': `Bearer ${OPENAI_API_KEY}`\n      },\n      body: JSON.stringify({\n        model: 'gpt-3.5-turbo',\n        messages: [\n          {\n            \"role\": \"system\",\n            \"content\": SYSTEM_PROMPT\n          },\n          {\n            \"role\": \"user\",\n            \"content\": query\n          }\n        ],\n        temperature: 0.7,\n        max_tokens: 150\n      })\n    });\n    \n    if (!response.ok) {\n      throw new Error(`OpenAI API error: ${response.status}`);\n    }\n    \n    const data = await response.json();\n    const answer = data.choices?.[0]?.message?.content?.trim();\n    \n    if (!answer) {\n      throw new Error('Empty response from OpenAI');\n    }\n    \n    return {\n      answer,\n      confidence: 0.9,\n      isTechQuestion: true,\n      source: \"openai\"\n    };\n    \n  } catch (error) {\n    console.error('Error calling OpenAI:', error);\n    return null;\n  }\n}\n\n/**\n * Generates a fallback response based on the query\n */\nfunction generateFallbackResponse(query: string): VoiceAssistantResponse {\n  // Check if it's a tech question\n  const techQuestion = isTechQuestion(query);\n  \n  if (!techQuestion) {\n    return {\n      answer: \"I'm sorry, I can only answer questions related to technology, AI, and computing. Please ask me about tech topics.\",\n      confidence: 0.9,\n      isTechQuestion: false,\n      source: \"fallback\"\n    };\n  }\n  \n  // For tech questions, provide responses from our knowledge base\n  \n  // General tech questions\n  if (query.toLowerCase().includes('what is') || query.toLowerCase().includes('how does')) {\n    return {\n      answer: `Based on the latest information, ${query.replace(/what is|how does/i, '').trim()} involves advanced technology that combines machine learning algorithms with specialized hardware. The most recent developments in this field focus on efficiency and accessibility.`,\n      confidence: 0.85,\n      isTechQuestion: true,\n      source: \"fallback\"\n    };\n  }\n  \n  // AI-specific questions\n  if (query.toLowerCase().includes('ai') || query.toLowerCase().includes('artificial intelligence')) {\n    return {\n      answer: \"Artificial Intelligence is rapidly evolving. Recent advancements include more powerful language models, multimodal capabilities, and improved reasoning. Companies like OpenAI, Anthropic, and Google are leading innovation in this space with models like GPT-4, Claude, and Gemini.\",\n      confidence: 0.9,\n      isTechQuestion: true,\n      source: \"fallback\"\n    };\n  }\n\n  // News-related tech questions\n  if (query.toLowerCase().includes('news') || query.toLowerCase().includes('latest') || query.toLowerCase().includes('recent')) {\n    return {\n      answer: \"The most recent tech news includes advancements in AI language models, new consumer devices, and breakthroughs in quantum computing. You can view the latest tech news in our news feed section.\",\n      confidence: 0.87,\n      isTechQuestion: true,\n      source: \"fallback\"\n    };\n  }\n  \n  // Fallback for other tech questions\n  return {\n    answer: \"That's an interesting technology question. While I don't have specific information on that, you might find relevant articles in our news feed or by searching our site for related topics.\",\n    confidence: 0.7,\n    isTechQuestion: true,\n    source: \"fallback\"\n  };\n}\n\nexport async function POST(request: Request) {\n  try {\n    // Parse the request body\n    const body: VoiceAssistantRequest = await request.json();\n    \n    if (!body.query) {\n      return NextResponse.json(\n        { error: 'Query is required' },\n        { status: 400 }\n      );\n    }\n    \n    // Log the query (for debugging)\n    console.log(`Voice assistant query: ${body.query}`);\n    \n    // Try to get a response from OpenAI first\n    const openAIResponse = await getOpenAIResponse(body.query);\n    \n    // If we got a valid response from OpenAI, use that\n    if (openAIResponse) {\n      return NextResponse.json(openAIResponse, { status: 200 });\n    }\n    \n    // Otherwise, fall back to our built-in response generator\n    const fallbackResponse = generateFallbackResponse(body.query);\n    \n    // Return the response\n    return NextResponse.json(fallbackResponse, { status: 200 });\n    \n  } catch (error: any) {\n    console.error('Error processing voice assistant query:', error);\n    \n    return NextResponse.json(\n      { \n        error: 'Failed to process query',\n        details: error.message \n      },\n      { status: 500 }\n    );\n  }\n}\n\n// For simple test queries via GET\nexport async function GET(request: Request) {\n  try {\n    const { searchParams } = new URL(request.url);\n    const query = searchParams.get('q');\n    \n    if (!query) {\n      return NextResponse.json(\n        { error: 'Query parameter q is required' },\n        { status: 400 }\n      );\n    }\n    \n    // Try to get a response from OpenAI first\n    const openAIResponse = await getOpenAIResponse(query);\n    \n    // If we got a valid response from OpenAI, use that\n    if (openAIResponse) {\n      return NextResponse.json(openAIResponse, { status: 200 });\n    }\n    \n    // Otherwise, fall back to our built-in response generator\n    const fallbackResponse = generateFallbackResponse(query);\n    \n    // Return the response\n    return NextResponse.json(fallbackResponse, { status: 200 });\n    \n  } catch (error: any) {\n    console.error('Error processing voice assistant query:', error);\n    \n    return NextResponse.json(\n      { \n        error: 'Failed to process query',\n        details: error.message \n      },\n      { status: 500 }\n    );\n  }\n} "],"names":[],"mappings":";;;;AAAA;;AAEA,qEAAqE;AACrE,MAAM,iBAAiB,QAAQ,GAAG,CAAC,cAAc;AAgBjD,wEAAwE;AACxE,MAAM,gBAAgB,CAAC;;;;;;;;mDAQ4B,CAAC;AAEpD,uEAAuE;AACvE,MAAM,gBAAgB;IACpB;IAAM;IAA2B;IAAoB;IAAM;IAC3D;IAAkB;IAAc;IAAY;IAAY;IAAY;IACpE;IAAQ;IAAa;IAAQ;IAAS;IAAY;IAAO;IAAO;IAChE;IAAU;IAAS;IAAY;IAAc;IAAS;IAAW;IACjE;IAAa;IAAQ;IAAiB;IAAU;IAAW;IAAW;IACtE;IAAa;IAAW;IAAO;IAAa;IAAY;IAAW;IACnE;IAAO;IAAO;IAAW;IAAmB;IAAM;IAAqB;IACvE;IAAc;IAAkB;IAAU;IAAW;IAAY;IACjE;IAAY;IAAc;IAAW;IAAa;IAAS;IAAS;IACpE;IAAa;IAAW;IAAO;IAAO;IAAwB;IAC9D;IAAU;IAAU;IAAa;IAAS;IAAU;IAAQ;IAC5D;IAAW;IAAK;IAAgB;IAAiB;IAAW;IAAU;IACtE;IAAc;IAAU;IAAU;IAAW;IAAU;IACvD;IAAQ;IAAQ;IAAQ;IAAU;IAAS;IAAS;IAAU;IAAO;IACrE;IAAU;IAAa;IAAU;IAAe;IAAa;IAC7D;IAAe;IAAoB;IAAM;IAA0B;CACpE;AAED;;CAEC,GACD,SAAS,eAAe,KAAa;IACnC,MAAM,aAAa,MAAM,WAAW;IACpC,OAAO,cAAc,IAAI,CAAC,CAAA,UAAW,WAAW,QAAQ,CAAC,QAAQ,WAAW;AAC9E;AAEA;;CAEC,GACD,eAAe,kBAAkB,KAAa;IAC5C,IAAI,CAAC,gBAAgB,OAAO;IAE5B,IAAI;QACF,MAAM,YAAY,eAAe;QAEjC,gEAAgE;QAChE,IAAI,CAAC,WAAW;YACd,OAAO;gBACL,QAAQ;gBACR,YAAY;gBACZ,gBAAgB;gBAChB,QAAQ;YACV;QACF;QAEA,MAAM,WAAW,MAAM,MAAM,8CAA8C;YACzE,QAAQ;YACR,SAAS;gBACP,gBAAgB;gBAChB,iBAAiB,CAAC,OAAO,EAAE,gBAAgB;YAC7C;YACA,MAAM,KAAK,SAAS,CAAC;gBACnB,OAAO;gBACP,UAAU;oBACR;wBACE,QAAQ;wBACR,WAAW;oBACb;oBACA;wBACE,QAAQ;wBACR,WAAW;oBACb;iBACD;gBACD,aAAa;gBACb,YAAY;YACd;QACF;QAEA,IAAI,CAAC,SAAS,EAAE,EAAE;YAChB,MAAM,IAAI,MAAM,CAAC,kBAAkB,EAAE,SAAS,MAAM,EAAE;QACxD;QAEA,MAAM,OAAO,MAAM,SAAS,IAAI;QAChC,MAAM,SAAS,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,SAAS;QAEpD,IAAI,CAAC,QAAQ;YACX,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO;YACL;YACA,YAAY;YACZ,gBAAgB;YAChB,QAAQ;QACV;IAEF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,OAAO;IACT;AACF;AAEA;;CAEC,GACD,SAAS,yBAAyB,KAAa;IAC7C,gCAAgC;IAChC,MAAM,eAAe,eAAe;IAEpC,IAAI,CAAC,cAAc;QACjB,OAAO;YACL,QAAQ;YACR,YAAY;YACZ,gBAAgB;YAChB,QAAQ;QACV;IACF;IAEA,gEAAgE;IAEhE,yBAAyB;IACzB,IAAI,MAAM,WAAW,GAAG,QAAQ,CAAC,cAAc,MAAM,WAAW,GAAG,QAAQ,CAAC,aAAa;QACvF,OAAO;YACL,QAAQ,CAAC,iCAAiC,EAAE,MAAM,OAAO,CAAC,qBAAqB,IAAI,IAAI,GAAG,oLAAoL,CAAC;YAC/Q,YAAY;YACZ,gBAAgB;YAChB,QAAQ;QACV;IACF;IAEA,wBAAwB;IACxB,IAAI,MAAM,WAAW,GAAG,QAAQ,CAAC,SAAS,MAAM,WAAW,GAAG,QAAQ,CAAC,4BAA4B;QACjG,OAAO;YACL,QAAQ;YACR,YAAY;YACZ,gBAAgB;YAChB,QAAQ;QACV;IACF;IAEA,8BAA8B;IAC9B,IAAI,MAAM,WAAW,GAAG,QAAQ,CAAC,WAAW,MAAM,WAAW,GAAG,QAAQ,CAAC,aAAa,MAAM,WAAW,GAAG,QAAQ,CAAC,WAAW;QAC5H,OAAO;YACL,QAAQ;YACR,YAAY;YACZ,gBAAgB;YAChB,QAAQ;QACV;IACF;IAEA,oCAAoC;IACpC,OAAO;QACL,QAAQ;QACR,YAAY;QACZ,gBAAgB;QAChB,QAAQ;IACV;AACF;AAEO,eAAe,KAAK,OAAgB;IACzC,IAAI;QACF,yBAAyB;QACzB,MAAM,OAA8B,MAAM,QAAQ,IAAI;QAEtD,IAAI,CAAC,KAAK,KAAK,EAAE;YACf,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAoB,GAC7B;gBAAE,QAAQ;YAAI;QAElB;QAEA,gCAAgC;QAChC,QAAQ,GAAG,CAAC,CAAC,uBAAuB,EAAE,KAAK,KAAK,EAAE;QAElD,0CAA0C;QAC1C,MAAM,iBAAiB,MAAM,kBAAkB,KAAK,KAAK;QAEzD,mDAAmD;QACnD,IAAI,gBAAgB;YAClB,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC,gBAAgB;gBAAE,QAAQ;YAAI;QACzD;QAEA,0DAA0D;QAC1D,MAAM,mBAAmB,yBAAyB,KAAK,KAAK;QAE5D,sBAAsB;QACtB,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC,kBAAkB;YAAE,QAAQ;QAAI;IAE3D,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,2CAA2C;QAEzD,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YACE,OAAO;YACP,SAAS,MAAM,OAAO;QACxB,GACA;YAAE,QAAQ;QAAI;IAElB;AACF;AAGO,eAAe,IAAI,OAAgB;IACxC,IAAI;QACF,MAAM,EAAE,YAAY,EAAE,GAAG,IAAI,IAAI,QAAQ,GAAG;QAC5C,MAAM,QAAQ,aAAa,GAAG,CAAC;QAE/B,IAAI,CAAC,OAAO;YACV,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAAgC,GACzC;gBAAE,QAAQ;YAAI;QAElB;QAEA,0CAA0C;QAC1C,MAAM,iBAAiB,MAAM,kBAAkB;QAE/C,mDAAmD;QACnD,IAAI,gBAAgB;YAClB,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC,gBAAgB;gBAAE,QAAQ;YAAI;QACzD;QAEA,0DAA0D;QAC1D,MAAM,mBAAmB,yBAAyB;QAElD,sBAAsB;QACtB,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC,kBAAkB;YAAE,QAAQ;QAAI;IAE3D,EAAE,OAAO,OAAY;QACnB,QAAQ,KAAK,CAAC,2CAA2C;QAEzD,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YACE,OAAO;YACP,SAAS,MAAM,OAAO;QACxB,GACA;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}},
    {"offset": {"line": 370, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"A"}}]
}